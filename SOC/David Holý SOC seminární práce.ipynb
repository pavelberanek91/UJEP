{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import NormalDist\n",
    "from sklearn.metrics import confusion_matrix, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "from numpy.typing import NDArray\n",
    "from dataclasses import dataclass ,field\n",
    "from typing import Any, Self, Deque\n",
    "import plotly.express as px\n",
    "from math import ceil, inf\n",
    "from collections import deque\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zdroj dat: https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>TA</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>132</td>\n",
       "      <td>N</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>68</td>\n",
       "      <td>M</td>\n",
       "      <td>ASY</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>141</td>\n",
       "      <td>N</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>57</td>\n",
       "      <td>M</td>\n",
       "      <td>ASY</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>115</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>57</td>\n",
       "      <td>F</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>LVH</td>\n",
       "      <td>174</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>38</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>173</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>918 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age Sex ChestPainType  RestingBP  Cholesterol FastingBS RestingECG   \n",
       "0     40   M           ATA        140          289         0     Normal  \\\n",
       "1     49   F           NAP        160          180         0     Normal   \n",
       "2     37   M           ATA        130          283         0         ST   \n",
       "3     48   F           ASY        138          214         0     Normal   \n",
       "4     54   M           NAP        150          195         0     Normal   \n",
       "..   ...  ..           ...        ...          ...       ...        ...   \n",
       "913   45   M            TA        110          264         0     Normal   \n",
       "914   68   M           ASY        144          193         1     Normal   \n",
       "915   57   M           ASY        130          131         0     Normal   \n",
       "916   57   F           ATA        130          236         0        LVH   \n",
       "917   38   M           NAP        138          175         0     Normal   \n",
       "\n",
       "     MaxHR ExerciseAngina  Oldpeak ST_Slope HeartDisease  \n",
       "0      172              N      0.0       Up            0  \n",
       "1      156              N      1.0     Flat            1  \n",
       "2       98              N      0.0       Up            0  \n",
       "3      108              Y      1.5     Flat            1  \n",
       "4      122              N      0.0       Up            0  \n",
       "..     ...            ...      ...      ...          ...  \n",
       "913    132              N      1.2     Flat            1  \n",
       "914    141              N      3.4     Flat            1  \n",
       "915    115              Y      1.2     Flat            1  \n",
       "916    174              N      0.0     Flat            1  \n",
       "917    173              N      0.0       Up            0  \n",
       "\n",
       "[918 rows x 12 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"heart.csv\", dtype={\n",
    "    \"Sex\":\"category\",\n",
    "    \"ChestPainType\": \"category\",\n",
    "    \"FastingBS\":\"category\",\n",
    "    \"RestingECG\":\"category\",\n",
    "    \"ExerciseAngina\":\"category\",\n",
    "    \"ST_Slope\":\"category\",\n",
    "    \"HeartDisease\":\"category\"\n",
    "    })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "HeartDisease=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "0",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "0",
         "offsetgroup": "0",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0"
         ],
         "xaxis": "x",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "HeartDisease=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "1",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "1",
         "offsetgroup": "1",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1",
          "1"
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "title": {
          "text": "HeartDisease"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "categoryarray": [
          "0",
          "1"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "HeartDisease"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar = px.histogram(df,x=\"HeartDisease\", color=\"HeartDisease\")\n",
    "bar.update_traces(showlegend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ChestPainType\"] = df[\"ChestPainType\"].map({'ATA':0,'NAP':1,'ASY':2,'TA':3})\n",
    "df[\"RestingECG\"] = df[\"RestingECG\"].map({\"Normal\":0,\"ST\":1,\"LVH\":2})\n",
    "df[\"ExerciseAngina\"] = df[\"ExerciseAngina\"].map({\"N\":0,\"Y\":1})\n",
    "df[\"ST_Slope\"] =  df[\"ST_Slope\"].map({\"Up\":0 ,\"Flat\":1,\"Down\":2})\n",
    "df[\"FastingBS\"] =  df[\"FastingBS\"].map({\"0\": 0, \"1\": 1})\n",
    "df[\"Sex\"] = df[\"Sex\"].map({'M':0,'F':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test = train_test_split(df,test_size=0.2,stratify=df[\"HeartDisease\"])\n",
    "y_test = x_test.pop(\"HeartDisease\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features: int,\n",
    "        beta1: float = 0.9,\n",
    "        beta2: float = 0.999,\n",
    "        epsilon: float = 1e-8,\n",
    "        lr: float = 0.004\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Adam optimizer\n",
    "\n",
    "        Args:\n",
    "            n_features (int): Number of features\n",
    "            beta1 (float, optional): Decay for first moment. Defaults to 0.9.\n",
    "            beta2 (float, optional): Decay for secodn moment. Defaults to 0.999.\n",
    "            epsilon (float, optional): Small value to prevent dividing by 0. Defaults to 1e-8.\n",
    "            lr (float, optional): Learning rate. Defaults to 0.004.\n",
    "        \"\"\"\n",
    "        self._counter = 1\n",
    "        self._weight_moments = np.zeros(n_features)\n",
    "        self._weight_variance, self._bias_variance = 0, 0\n",
    "        self._bias_moments = 0\n",
    "        self._beta1 = beta1\n",
    "        self._beta2 = beta2\n",
    "        self._epsilon = epsilon\n",
    "        self._lr = lr\n",
    "            \n",
    "    def step(self, gradient_weights: NDArray[np.float32], gradient_bias: NDArray[np.bool_]) -> tuple:\n",
    "        \"\"\"\n",
    "        Calculate optimizing step\n",
    "\n",
    "        Args:\n",
    "            gradient_weights (NDArray[np.float32]): Calculated gradients of model weights.\n",
    "            gradient_bias (NDArray[np.bool_]): Calculated bias of model.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Tuple where first item is step for weights and second for bias.\n",
    "        \"\"\"\n",
    "        # Update moment vectors\n",
    "        self._weight_moments = self._beta1 * self._weight_moments + (1 - self._beta1) * gradient_weights\n",
    "        self._bias_moments = self._beta1 * self._bias_moments + (1 - self._beta1) * gradient_bias\n",
    "\n",
    "        #rms \n",
    "        self._weight_variance = self._beta2 * self._weight_variance + (1 - self._beta2) * (gradient_weights ** 2)\n",
    "        self._bias_variance = self._beta2 * self._bias_variance + (1 - self._beta2) * gradient_bias\n",
    "\n",
    "        # Bias correction for moment vectors\n",
    "        m_hat = self._weight_moments / (1 - self._beta1 ** self._counter)\n",
    "        m_b_hat = self._bias_moments / (1 - self._beta1 ** self._counter)\n",
    "        \n",
    "        v_hat = self._weight_variance / (1 - self._beta2 ** self._counter)\n",
    "        v_b_hat = self._bias_variance / (1 - self._beta2 ** self._counter)\n",
    "\n",
    "        self._counter += 1\n",
    "        return self._lr * (m_hat / (np.sqrt(np.abs(v_hat) + self._epsilon))), self._lr * (m_b_hat / (np.sqrt(np.abs(v_b_hat) + self._epsilon)))\n",
    "\n",
    "class SVM:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features: int,\n",
    "        learning_rate: float =0.001,\n",
    "        lambda_param: float = 0.01,\n",
    "        num_iterations: int = 1000,\n",
    "        beta1: float  = 0.9,\n",
    "        beta2: float  = 0.999,\n",
    "        epsilon: float = 1e-8\n",
    "    ):\n",
    "        \"\"\"\n",
    "        SVM model.\n",
    "\n",
    "        Args:\n",
    "            n_features (int): Number of input features to the model\n",
    "            learning_rate (float, optional): Learning grade ffor optimization. Defaults to 0.001.\n",
    "            lambda_param (float, optional): Constrain checking constant. Defaults to 0.01.\n",
    "            num_iterations (int, optional): Number of iterations for optimization. Defaults to 1000.\n",
    "            beta1 (float, optional): Adam optimizer argument. Defaults to 0.9.\n",
    "            beta2 (float, optional): Adam optimizer argument. Defaults to 0.999.\n",
    "            epsilon (float, optional): Adam optimizer argument. Defaults to 1e-8.\n",
    "        \"\"\"\n",
    "        self._optimizer = Adam(n_features= n_features, beta1 = beta1, beta2 = beta2, epsilon = epsilon, lr = learning_rate)\n",
    "        self._learning_rate = learning_rate\n",
    "        self._lr = lambda_param\n",
    "        self._num_iterations = num_iterations\n",
    "        self._bias = np.random.randn() + 0.001\n",
    "    \n",
    "    def _satisfy_constraint(self, x: NDArray, y: NDArray) -> NDArray[np.bool_]:\n",
    "        \"\"\"\n",
    "        Calculate condition for each sample\n",
    "\n",
    "        Args:\n",
    "            x (NDArray): Array of features\n",
    "            y (NDArray): Array of targeted feature\n",
    "\n",
    "        Returns:\n",
    "            NDArray[np.bool_]: If constrain is satisfied for each sample/\n",
    "        \"\"\"\n",
    "        linear = np.dot(x, self._weights) + self._bias\n",
    "        return (y * linear >= 1).astype(int)\n",
    "    \n",
    "    def _get_gradients(self, constrain: NDArray[np.bool_],x: NDArray,y: NDArray) -> tuple:\n",
    "        \"\"\"\n",
    "        Calculate gradient for svm  model.\n",
    "\n",
    "        Args:\n",
    "            constrain (NDArray[np.bool_]): if the constrain is satisfied for each sample.\n",
    "            x (_type_): Array of features.\n",
    "            y (_type_): Array of targeted feature.\n",
    "\n",
    "        Returns:\n",
    "            tuple: First value is gradient for weaight ans second for bias.\n",
    "        \"\"\"\n",
    "        constrain = np.expand_dims(constrain,-1)\n",
    "        grad =  constrain * self._weights + (1 - constrain) * (self._weights - np.expand_dims(y,-1) * x)\n",
    "        bias = (1 - constrain) * np.expand_dims(-y,-1)\n",
    "        return grad, bias\n",
    "        \n",
    "    def fit(self, x: NDArray, y: NDArray , batch_size: int = 64) -> None:\n",
    "        \"\"\"\n",
    "        Fit the model.\n",
    "\n",
    "        Args:\n",
    "            x (NDArray): Two dimensional array of features. First dimension is for samples, second for feature \n",
    "            y (NDArray): One dimensional array of targeted feature.\n",
    "            batch_size (int, optional): Batch size for gradient step. Defaults to 64.\n",
    "        \"\"\"\n",
    "        y =  np.where( y <= 0, -1,1)\n",
    "        n_features = x.shape[-1]\n",
    "        data = np.concatenate((x,np.expand_dims(y,-1)),axis=1)\n",
    "\n",
    "        # Initialize the model parameters\n",
    "        self._weights = np.zeros(n_features, dtype=np.float64)\n",
    "        self._bias = 0\n",
    "\n",
    "        for _ in range(self._num_iterations):\n",
    "            #shuffle and split\n",
    "            np.random.shuffle(data)\n",
    "            y = np.array_split(data[:,-1], ceil(data.shape[0]/batch_size)) # type: ignore\n",
    "            x = np.array_split(data[:,:-1], ceil(data.shape[0]/batch_size)) # type: ignore\n",
    "            gradients = 0\n",
    "            for x_batch, y_batch in zip(x,y):\n",
    "                #map binary input to {-1,1}\n",
    "                constrains = self._satisfy_constraint(x_batch,y_batch)\n",
    "                res = self._get_gradients(constrains,x_batch,y_batch)\n",
    "                gradient = np.sum(res[0],0)/x_batch.shape[0]\n",
    "                bias = np.sum(res[1],0)/x_batch.shape[0]\n",
    "                \n",
    "                gradients += np.sum(gradient) + np.sum(bias)\n",
    "\n",
    "                # Update weights and bias with Adam optimizer\n",
    "                step = self._optimizer.step(gradient, bias)\n",
    "                self._weights -= step[0]\n",
    "                self._bias -= step[1]\n",
    "                # self._weights -= self._optimizer._lr * gradient\n",
    "                # self._bias -= self._optimizer._lr * bias\n",
    "            print(f\"iteration: {_} grad_size: {gradients}\")\n",
    "\n",
    "    def predict(self, x: NDArray) -> NDArray:\n",
    "        \"\"\"\n",
    "        Predict feature for given rows \n",
    "\n",
    "        Args:\n",
    "            x (NDArray): two dimensional input data. First dimension are samples, second features.\n",
    "\n",
    "        Returns:\n",
    "            NDArray: Predicted feature for each sample.\n",
    "        \"\"\"\n",
    "        # Compute the predicted class labels\n",
    "        scores = np.dot(x, self._weights) + self._bias\n",
    "        scores = np.sign(scores)\n",
    "        return np.where(scores == -1, 0, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "data pochÃ¡zejÃ­ z odkazu https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 grad_size: -570.3335096736804\n",
      "iteration: 1 grad_size: -564.4840330353323\n",
      "iteration: 2 grad_size: -561.1280389282784\n",
      "iteration: 3 grad_size: -561.363418849095\n",
      "iteration: 4 grad_size: -566.9273863663117\n",
      "iteration: 5 grad_size: -567.9324670035543\n",
      "iteration: 6 grad_size: -573.3267380822613\n",
      "iteration: 7 grad_size: -568.970751925629\n",
      "iteration: 8 grad_size: -573.3406411185413\n",
      "iteration: 9 grad_size: -569.8311552649326\n",
      "iteration: 10 grad_size: -569.4990978118834\n",
      "iteration: 11 grad_size: -574.1949510294008\n",
      "iteration: 12 grad_size: -571.8403106525541\n",
      "iteration: 13 grad_size: -567.334050615101\n",
      "iteration: 14 grad_size: -559.1071523394788\n",
      "iteration: 15 grad_size: -565.8525989294014\n",
      "iteration: 16 grad_size: -565.3443479860648\n",
      "iteration: 17 grad_size: -567.0315977465759\n",
      "iteration: 18 grad_size: -573.0127307043889\n",
      "iteration: 19 grad_size: -572.8696903177419\n",
      "iteration: 20 grad_size: -562.1947077579001\n",
      "iteration: 21 grad_size: -568.5129372688206\n",
      "iteration: 22 grad_size: -557.9121397477794\n",
      "iteration: 23 grad_size: -556.3874654844882\n",
      "iteration: 24 grad_size: -532.0259480870894\n",
      "iteration: 25 grad_size: -493.3603375335439\n",
      "iteration: 26 grad_size: -450.5401232130448\n",
      "iteration: 27 grad_size: -372.3328285507856\n",
      "iteration: 28 grad_size: -293.298700593588\n",
      "iteration: 29 grad_size: -209.38577918954397\n",
      "iteration: 30 grad_size: -95.42377807703372\n",
      "iteration: 31 grad_size: -63.713770491731665\n",
      "iteration: 32 grad_size: -63.66547716516686\n",
      "iteration: 33 grad_size: 5.354485311536269\n",
      "iteration: 34 grad_size: 17.112886395082562\n",
      "iteration: 35 grad_size: 29.329251496544842\n",
      "iteration: 36 grad_size: 122.4497376824356\n",
      "iteration: 37 grad_size: 116.77080774739048\n",
      "iteration: 38 grad_size: 137.62943665273036\n",
      "iteration: 39 grad_size: 149.08228999607138\n",
      "iteration: 40 grad_size: 83.17902744882409\n",
      "iteration: 41 grad_size: 129.17340743183746\n",
      "iteration: 42 grad_size: 146.12911801957844\n",
      "iteration: 43 grad_size: 87.61271659985998\n",
      "iteration: 44 grad_size: 131.22596571818613\n",
      "iteration: 45 grad_size: 138.93503787456712\n",
      "iteration: 46 grad_size: 92.78368786465673\n",
      "iteration: 47 grad_size: 96.6158808323872\n",
      "iteration: 48 grad_size: 103.04879700912429\n",
      "iteration: 49 grad_size: 117.30611646072333\n",
      "iteration: 50 grad_size: 117.77802472576593\n",
      "iteration: 51 grad_size: 132.91528778154932\n",
      "iteration: 52 grad_size: 119.77995809884766\n",
      "iteration: 53 grad_size: 106.56480620375814\n",
      "iteration: 54 grad_size: 121.15791978302204\n",
      "iteration: 55 grad_size: 118.88124869608112\n",
      "iteration: 56 grad_size: 151.3083497019823\n",
      "iteration: 57 grad_size: 159.41705468714215\n",
      "iteration: 58 grad_size: 168.6450014017613\n",
      "iteration: 59 grad_size: 152.1825288574008\n",
      "iteration: 60 grad_size: 133.97742697021778\n",
      "iteration: 61 grad_size: 101.66315221344135\n",
      "iteration: 62 grad_size: 118.2454956182836\n",
      "iteration: 63 grad_size: 122.22211875610833\n",
      "iteration: 64 grad_size: 111.33142932317226\n",
      "iteration: 65 grad_size: 129.88429728662558\n",
      "iteration: 66 grad_size: 128.0085352050438\n",
      "iteration: 67 grad_size: 126.48198803991171\n",
      "iteration: 68 grad_size: 133.60179350252793\n",
      "iteration: 69 grad_size: 141.54329283685328\n",
      "iteration: 70 grad_size: 136.588977796539\n",
      "iteration: 71 grad_size: 133.79974542448443\n",
      "iteration: 72 grad_size: 130.75978386032344\n",
      "iteration: 73 grad_size: 143.4258764277841\n",
      "iteration: 74 grad_size: 129.1035126906641\n",
      "iteration: 75 grad_size: 137.73063122725034\n",
      "iteration: 76 grad_size: 122.20101575594967\n",
      "iteration: 77 grad_size: 146.32726584361563\n",
      "iteration: 78 grad_size: 145.67631035699227\n",
      "iteration: 79 grad_size: 127.77057163107128\n",
      "iteration: 80 grad_size: 149.23420032874455\n",
      "iteration: 81 grad_size: 152.4292259374753\n",
      "iteration: 82 grad_size: 151.14140560611605\n",
      "iteration: 83 grad_size: 120.51398429710159\n",
      "iteration: 84 grad_size: 120.12672396188317\n",
      "iteration: 85 grad_size: 121.08193300190659\n",
      "iteration: 86 grad_size: 106.92515567928801\n",
      "iteration: 87 grad_size: 134.31683071198069\n",
      "iteration: 88 grad_size: 152.1031705922295\n",
      "iteration: 89 grad_size: 108.86214514508757\n",
      "iteration: 90 grad_size: 126.52551448538793\n",
      "iteration: 91 grad_size: 132.77853085657497\n",
      "iteration: 92 grad_size: 145.7639935869713\n",
      "iteration: 93 grad_size: 114.30866362075813\n",
      "iteration: 94 grad_size: 115.30080680582672\n",
      "iteration: 95 grad_size: 100.884095680661\n",
      "iteration: 96 grad_size: 107.35410156425716\n",
      "iteration: 97 grad_size: 94.32457047753414\n",
      "iteration: 98 grad_size: 109.95871047910968\n",
      "iteration: 99 grad_size: 123.71571664539479\n",
      "iteration: 100 grad_size: 115.1369449130609\n",
      "iteration: 101 grad_size: 134.96102608131568\n",
      "iteration: 102 grad_size: 127.59238617165991\n",
      "iteration: 103 grad_size: 121.11240739070621\n",
      "iteration: 104 grad_size: 105.02246025790843\n",
      "iteration: 105 grad_size: 91.30212340772731\n",
      "iteration: 106 grad_size: 136.1943000984903\n",
      "iteration: 107 grad_size: 97.61609842726432\n",
      "iteration: 108 grad_size: 97.92598813212302\n",
      "iteration: 109 grad_size: 112.47488391702095\n",
      "iteration: 110 grad_size: 120.38610840905896\n",
      "iteration: 111 grad_size: 115.73703086250045\n",
      "iteration: 112 grad_size: 132.36463248502037\n",
      "iteration: 113 grad_size: 105.901905261701\n",
      "iteration: 114 grad_size: 121.85564563252046\n",
      "iteration: 115 grad_size: 112.25132841229043\n",
      "iteration: 116 grad_size: 101.84246468439665\n",
      "iteration: 117 grad_size: 121.57883211779202\n",
      "iteration: 118 grad_size: 127.00764005516645\n",
      "iteration: 119 grad_size: 124.12335942459171\n",
      "iteration: 120 grad_size: 122.3828646305103\n",
      "iteration: 121 grad_size: 126.32357109503582\n",
      "iteration: 122 grad_size: 117.21321622532207\n",
      "iteration: 123 grad_size: 115.5345482384354\n",
      "iteration: 124 grad_size: 107.49963073830429\n",
      "iteration: 125 grad_size: 110.19213628538814\n",
      "iteration: 126 grad_size: 123.63802082393721\n",
      "iteration: 127 grad_size: 97.30610119182295\n",
      "iteration: 128 grad_size: 103.5212280459385\n",
      "iteration: 129 grad_size: 49.93266351152059\n",
      "iteration: 130 grad_size: 46.60426167385704\n",
      "iteration: 131 grad_size: 52.56111824473828\n",
      "iteration: 132 grad_size: 36.007726299666\n",
      "iteration: 133 grad_size: 35.4964875374946\n",
      "iteration: 134 grad_size: 37.05616827298577\n",
      "iteration: 135 grad_size: 53.24490992624872\n",
      "iteration: 136 grad_size: 56.67093726295336\n",
      "iteration: 137 grad_size: 54.71418690721167\n",
      "iteration: 138 grad_size: 57.88018393104165\n",
      "iteration: 139 grad_size: 56.630576574363175\n",
      "iteration: 140 grad_size: 54.81218668705313\n",
      "iteration: 141 grad_size: 57.42367812910989\n",
      "iteration: 142 grad_size: 40.113194093659075\n",
      "iteration: 143 grad_size: 2.0854337367361353\n",
      "iteration: 144 grad_size: -15.881492742123612\n",
      "iteration: 145 grad_size: 25.2905601487179\n",
      "iteration: 146 grad_size: 51.49575265378371\n",
      "iteration: 147 grad_size: 3.0764716944566146\n",
      "iteration: 148 grad_size: 8.611809078561267\n",
      "iteration: 149 grad_size: 1.4509965274935492\n",
      "iteration: 150 grad_size: -15.115957748241073\n",
      "iteration: 151 grad_size: -9.814329741047452\n",
      "iteration: 152 grad_size: -8.438651239452412\n",
      "iteration: 153 grad_size: -33.53228021789495\n",
      "iteration: 154 grad_size: -47.84682910180269\n",
      "iteration: 155 grad_size: -7.025135402815536\n",
      "iteration: 156 grad_size: -3.141172857359976\n",
      "iteration: 157 grad_size: 6.40659895035941\n",
      "iteration: 158 grad_size: -3.1311596870075746\n",
      "iteration: 159 grad_size: 5.308066385972154\n",
      "iteration: 160 grad_size: -15.659255292096375\n",
      "iteration: 161 grad_size: -19.315643498397776\n",
      "iteration: 162 grad_size: 5.434367549466799\n",
      "iteration: 163 grad_size: -21.19439884272994\n",
      "iteration: 164 grad_size: -43.14324922764321\n",
      "iteration: 165 grad_size: -38.53273386530769\n",
      "iteration: 166 grad_size: -35.221348077070324\n",
      "iteration: 167 grad_size: 2.5234169595405547\n",
      "iteration: 168 grad_size: -67.14105980987752\n",
      "iteration: 169 grad_size: -61.33718844375658\n",
      "iteration: 170 grad_size: -45.372857037823366\n",
      "iteration: 171 grad_size: -20.952518888385967\n",
      "iteration: 172 grad_size: -10.362853477761917\n",
      "iteration: 173 grad_size: -63.54684675636118\n",
      "iteration: 174 grad_size: -70.66286443774806\n",
      "iteration: 175 grad_size: -89.92679077269484\n",
      "iteration: 176 grad_size: -39.73382680107201\n",
      "iteration: 177 grad_size: -3.2427432219543277\n",
      "iteration: 178 grad_size: 44.1432508499783\n",
      "iteration: 179 grad_size: -41.048769249890746\n",
      "iteration: 180 grad_size: -88.48720695316996\n",
      "iteration: 181 grad_size: -59.42392441632038\n",
      "iteration: 182 grad_size: 6.787948599004366\n",
      "iteration: 183 grad_size: -25.372870525560607\n",
      "iteration: 184 grad_size: 19.722050331450745\n",
      "iteration: 185 grad_size: -30.92747835200556\n",
      "iteration: 186 grad_size: -25.15226180989431\n",
      "iteration: 187 grad_size: -90.7266810859538\n",
      "iteration: 188 grad_size: -95.0691924651725\n",
      "iteration: 189 grad_size: -50.67572739245207\n",
      "iteration: 190 grad_size: 20.02833784750505\n",
      "iteration: 191 grad_size: 19.368436925250435\n",
      "iteration: 192 grad_size: -12.152993133904458\n",
      "iteration: 193 grad_size: -4.002965960933409\n",
      "iteration: 194 grad_size: -56.82338975180802\n",
      "iteration: 195 grad_size: -21.22289507900087\n",
      "iteration: 196 grad_size: 5.395747096041362\n",
      "iteration: 197 grad_size: -95.42828418073822\n",
      "iteration: 198 grad_size: -119.6600831320905\n",
      "iteration: 199 grad_size: -53.54086237167418\n",
      "iteration: 200 grad_size: -95.93158662167852\n",
      "iteration: 201 grad_size: -95.0988859326605\n",
      "iteration: 202 grad_size: -22.455856529052255\n",
      "iteration: 203 grad_size: -76.45515086498688\n",
      "iteration: 204 grad_size: 29.5654419062232\n",
      "iteration: 205 grad_size: -40.110850541219854\n",
      "iteration: 206 grad_size: -92.86497623993989\n",
      "iteration: 207 grad_size: 9.622521693982918\n",
      "iteration: 208 grad_size: -114.2584614492317\n",
      "iteration: 209 grad_size: -103.1101622537227\n",
      "iteration: 210 grad_size: -14.25518965741567\n",
      "iteration: 211 grad_size: -33.75948491738859\n",
      "iteration: 212 grad_size: -41.09679310172763\n",
      "iteration: 213 grad_size: -39.459986104465266\n",
      "iteration: 214 grad_size: -29.462084986653032\n",
      "iteration: 215 grad_size: -34.477432637441595\n",
      "iteration: 216 grad_size: -79.15458078176896\n",
      "iteration: 217 grad_size: -60.171646823560835\n",
      "iteration: 218 grad_size: -27.08151976903924\n",
      "iteration: 219 grad_size: -51.166703906934025\n",
      "iteration: 220 grad_size: -23.13851204066451\n",
      "iteration: 221 grad_size: 37.564503835585114\n",
      "iteration: 222 grad_size: 43.85022243983322\n",
      "iteration: 223 grad_size: -115.12166087690467\n",
      "iteration: 224 grad_size: -24.621293910344583\n",
      "iteration: 225 grad_size: -48.85415495316758\n",
      "iteration: 226 grad_size: -56.91326448361882\n",
      "iteration: 227 grad_size: -90.57068652730658\n",
      "iteration: 228 grad_size: -52.214089949193834\n",
      "iteration: 229 grad_size: 3.4282611640439313\n",
      "iteration: 230 grad_size: 6.219218662241275\n",
      "iteration: 231 grad_size: 7.187127583306648\n",
      "iteration: 232 grad_size: -51.81911668350225\n",
      "iteration: 233 grad_size: -15.906507511281426\n",
      "iteration: 234 grad_size: -12.47568033218397\n",
      "iteration: 235 grad_size: -33.10134199077885\n",
      "iteration: 236 grad_size: -99.05665547987182\n",
      "iteration: 237 grad_size: -51.14994776600547\n",
      "iteration: 238 grad_size: -68.08411961462792\n",
      "iteration: 239 grad_size: -12.655319340849577\n",
      "iteration: 240 grad_size: -31.27202134303953\n",
      "iteration: 241 grad_size: -12.804128407666465\n",
      "iteration: 242 grad_size: -53.95234589220987\n",
      "iteration: 243 grad_size: -27.16894131717634\n",
      "iteration: 244 grad_size: -88.56156053953202\n",
      "iteration: 245 grad_size: -57.36310689387793\n",
      "iteration: 246 grad_size: -39.453304161164525\n",
      "iteration: 247 grad_size: -46.1661627041557\n",
      "iteration: 248 grad_size: -72.31717720771033\n",
      "iteration: 249 grad_size: -69.0931045800701\n",
      "iteration: 250 grad_size: -67.0637373887892\n",
      "iteration: 251 grad_size: -65.29547773548983\n",
      "iteration: 252 grad_size: -89.7874061311646\n",
      "iteration: 253 grad_size: -6.364085492078431\n",
      "iteration: 254 grad_size: -32.044640264719916\n",
      "iteration: 255 grad_size: -30.58243635766606\n",
      "iteration: 256 grad_size: -25.56039264567625\n",
      "iteration: 257 grad_size: -27.09352089005376\n",
      "iteration: 258 grad_size: -30.48082470363049\n",
      "iteration: 259 grad_size: -53.19591977604837\n",
      "iteration: 260 grad_size: -5.717259453505662\n",
      "iteration: 261 grad_size: 33.68109340050361\n",
      "iteration: 262 grad_size: -27.28951572501056\n",
      "iteration: 263 grad_size: -67.80115298525062\n",
      "iteration: 264 grad_size: -69.41975460078997\n",
      "iteration: 265 grad_size: -7.989171744359737\n",
      "iteration: 266 grad_size: -4.250032903567302\n",
      "iteration: 267 grad_size: -32.25818922572002\n",
      "iteration: 268 grad_size: -54.799615701434824\n",
      "iteration: 269 grad_size: -11.403100336821012\n",
      "iteration: 270 grad_size: -9.515976060214939\n",
      "iteration: 271 grad_size: -53.3363506333657\n",
      "iteration: 272 grad_size: 48.27484465159188\n",
      "iteration: 273 grad_size: 0.16610543767006902\n",
      "iteration: 274 grad_size: -41.86381388096518\n",
      "iteration: 275 grad_size: 30.66411842527856\n",
      "iteration: 276 grad_size: -7.890346656798414\n",
      "iteration: 277 grad_size: -32.561222629975\n",
      "iteration: 278 grad_size: -41.38522094877726\n",
      "iteration: 279 grad_size: -19.541646912752192\n",
      "iteration: 280 grad_size: -9.66168482392331\n",
      "iteration: 281 grad_size: -14.74898268857011\n",
      "iteration: 282 grad_size: 10.714662402492337\n",
      "iteration: 283 grad_size: 4.088204689224881\n",
      "iteration: 284 grad_size: -78.2904487969497\n",
      "iteration: 285 grad_size: -51.84911396451204\n",
      "iteration: 286 grad_size: -33.94879701772563\n",
      "iteration: 287 grad_size: -13.766097266887641\n",
      "iteration: 288 grad_size: -29.446868543878296\n",
      "iteration: 289 grad_size: -55.39908269117036\n",
      "iteration: 290 grad_size: -33.7189189680428\n",
      "iteration: 291 grad_size: -11.77070114540377\n",
      "iteration: 292 grad_size: 7.255699671065962\n",
      "iteration: 293 grad_size: 16.44706358363794\n",
      "iteration: 294 grad_size: 61.39501235777638\n",
      "iteration: 295 grad_size: -19.742995153565516\n",
      "iteration: 296 grad_size: -118.80964079715731\n",
      "iteration: 297 grad_size: 20.192727099608167\n",
      "iteration: 298 grad_size: 16.380466481206142\n",
      "iteration: 299 grad_size: 24.200699330571183\n",
      "iteration: 300 grad_size: -18.267262660104027\n",
      "iteration: 301 grad_size: -55.99700274876369\n",
      "iteration: 302 grad_size: -56.478880045385175\n",
      "iteration: 303 grad_size: -12.873787401122527\n",
      "iteration: 304 grad_size: 4.117443701301411\n",
      "iteration: 305 grad_size: 3.9625802274030804\n",
      "iteration: 306 grad_size: -8.722988275012128\n",
      "iteration: 307 grad_size: -37.9590522738011\n",
      "iteration: 308 grad_size: -66.64703504700174\n",
      "iteration: 309 grad_size: -42.45851864378639\n",
      "iteration: 310 grad_size: -11.613837690719237\n",
      "iteration: 311 grad_size: 6.597054581204077\n",
      "iteration: 312 grad_size: -41.655314659067216\n",
      "iteration: 313 grad_size: -40.8827039943762\n",
      "iteration: 314 grad_size: 44.37602078001273\n",
      "iteration: 315 grad_size: 4.768784600846622\n",
      "iteration: 316 grad_size: -22.725662454550577\n",
      "iteration: 317 grad_size: 19.56014897892605\n",
      "iteration: 318 grad_size: 25.6816866802315\n",
      "iteration: 319 grad_size: -58.185263709385744\n",
      "iteration: 320 grad_size: -90.95542872836339\n",
      "iteration: 321 grad_size: -82.57382969947562\n",
      "iteration: 322 grad_size: 57.94778481559604\n",
      "iteration: 323 grad_size: 80.83207535965806\n",
      "iteration: 324 grad_size: 20.634587009454492\n",
      "iteration: 325 grad_size: 48.11886837080517\n",
      "iteration: 326 grad_size: -4.086205135702706\n",
      "iteration: 327 grad_size: -57.79448216622589\n",
      "iteration: 328 grad_size: -29.61905185170165\n",
      "iteration: 329 grad_size: -44.3351623816649\n",
      "iteration: 330 grad_size: 0.579034418942836\n",
      "iteration: 331 grad_size: 4.558203547715397\n",
      "iteration: 332 grad_size: 3.0987979989255514\n",
      "iteration: 333 grad_size: -18.365999959875687\n",
      "iteration: 334 grad_size: -41.85938390362415\n",
      "iteration: 335 grad_size: -2.187657092226125\n",
      "iteration: 336 grad_size: -45.408541108218465\n",
      "iteration: 337 grad_size: -46.64515484267436\n",
      "iteration: 338 grad_size: -24.00809652368185\n",
      "iteration: 339 grad_size: -23.02116023459628\n",
      "iteration: 340 grad_size: -21.7810686855102\n",
      "iteration: 341 grad_size: 17.60652589257041\n",
      "iteration: 342 grad_size: -20.179983129874103\n",
      "iteration: 343 grad_size: -24.52148642368269\n",
      "iteration: 344 grad_size: -84.62097351563459\n",
      "iteration: 345 grad_size: -3.511823219099675\n",
      "iteration: 346 grad_size: -20.412189426760822\n",
      "iteration: 347 grad_size: 18.046318455106906\n",
      "iteration: 348 grad_size: 24.540505780577938\n",
      "iteration: 349 grad_size: 40.48333520354079\n",
      "iteration: 350 grad_size: -15.568134723269004\n",
      "iteration: 351 grad_size: -45.42709807019173\n",
      "iteration: 352 grad_size: -16.729896633948997\n",
      "iteration: 353 grad_size: -20.468610763228888\n",
      "iteration: 354 grad_size: -30.470602407904458\n",
      "iteration: 355 grad_size: 19.931504573232957\n",
      "iteration: 356 grad_size: -14.691807660269774\n",
      "iteration: 357 grad_size: 22.22997121740015\n",
      "iteration: 358 grad_size: 19.230378698281655\n",
      "iteration: 359 grad_size: 25.8398864212961\n",
      "iteration: 360 grad_size: 23.830855057224177\n",
      "iteration: 361 grad_size: 24.149218528788936\n",
      "iteration: 362 grad_size: 0.5283536486855809\n",
      "iteration: 363 grad_size: -9.747451079614791\n",
      "iteration: 364 grad_size: -18.420791660593387\n",
      "iteration: 365 grad_size: -18.65563214216599\n",
      "iteration: 366 grad_size: 7.066804948643679\n",
      "iteration: 367 grad_size: 7.563185248768633\n",
      "iteration: 368 grad_size: 21.313363177990702\n",
      "iteration: 369 grad_size: -35.269920973930795\n",
      "iteration: 370 grad_size: -68.30167521458633\n",
      "iteration: 371 grad_size: -22.932645763865295\n",
      "iteration: 372 grad_size: 41.47005964036214\n",
      "iteration: 373 grad_size: -55.845873486789\n",
      "iteration: 374 grad_size: 15.119024799723519\n",
      "iteration: 375 grad_size: -15.453137032075716\n",
      "iteration: 376 grad_size: -39.85192108686739\n",
      "iteration: 377 grad_size: -128.0735290998524\n",
      "iteration: 378 grad_size: 46.23272984348935\n",
      "iteration: 379 grad_size: 74.91657669830253\n",
      "iteration: 380 grad_size: 21.59670118341529\n",
      "iteration: 381 grad_size: 33.7152033016944\n",
      "iteration: 382 grad_size: 20.193325204850108\n",
      "iteration: 383 grad_size: 19.10491075220856\n",
      "iteration: 384 grad_size: -20.88077350416892\n",
      "iteration: 385 grad_size: -19.459201338821558\n",
      "iteration: 386 grad_size: -74.03701675530597\n",
      "iteration: 387 grad_size: -76.95011562673542\n",
      "iteration: 388 grad_size: -76.41457961998829\n",
      "iteration: 389 grad_size: 23.990440461078283\n",
      "iteration: 390 grad_size: 48.62395161275853\n",
      "iteration: 391 grad_size: -29.17403260240883\n",
      "iteration: 392 grad_size: -73.90497827548097\n",
      "iteration: 393 grad_size: 10.435516916294008\n",
      "iteration: 394 grad_size: 20.811774516864403\n",
      "iteration: 395 grad_size: -38.61750069619385\n",
      "iteration: 396 grad_size: -45.65366839061117\n",
      "iteration: 397 grad_size: 57.73330542977291\n",
      "iteration: 398 grad_size: -68.66130593249963\n",
      "iteration: 399 grad_size: -70.95356138927538\n",
      "iteration: 400 grad_size: -37.99872153733226\n",
      "iteration: 401 grad_size: 56.88147561880346\n",
      "iteration: 402 grad_size: -84.76611341129166\n",
      "iteration: 403 grad_size: -72.20239540039243\n",
      "iteration: 404 grad_size: -20.352399823283044\n",
      "iteration: 405 grad_size: -23.9786318880749\n",
      "iteration: 406 grad_size: -37.209073337355\n",
      "iteration: 407 grad_size: -18.635105091211187\n",
      "iteration: 408 grad_size: 33.73304270559021\n",
      "iteration: 409 grad_size: -4.749323420499003\n",
      "iteration: 410 grad_size: -2.4144175639661647\n",
      "iteration: 411 grad_size: -103.4373446696197\n",
      "iteration: 412 grad_size: -23.507252850588785\n",
      "iteration: 413 grad_size: 16.17244577387946\n",
      "iteration: 414 grad_size: 39.857842602457026\n",
      "iteration: 415 grad_size: -28.616799084612424\n",
      "iteration: 416 grad_size: 4.9109360981794055\n",
      "iteration: 417 grad_size: 12.991859019461245\n",
      "iteration: 418 grad_size: -41.08414588149369\n",
      "iteration: 419 grad_size: -45.94368246994274\n",
      "iteration: 420 grad_size: -19.19036853962946\n",
      "iteration: 421 grad_size: -0.5682259321211518\n",
      "iteration: 422 grad_size: 16.320146380256432\n",
      "iteration: 423 grad_size: 19.479168853681657\n",
      "iteration: 424 grad_size: -5.09280373312869\n",
      "iteration: 425 grad_size: -47.67260605984137\n",
      "iteration: 426 grad_size: 0.47794635261060314\n",
      "iteration: 427 grad_size: -0.679412468921484\n",
      "iteration: 428 grad_size: -24.15713728630442\n",
      "iteration: 429 grad_size: 4.637429875359402\n",
      "iteration: 430 grad_size: -1.5607538150737286\n",
      "iteration: 431 grad_size: -24.041988494178003\n",
      "iteration: 432 grad_size: -38.67870426698978\n",
      "iteration: 433 grad_size: 0.07853824525447806\n",
      "iteration: 434 grad_size: -1.1624612180385512\n",
      "iteration: 435 grad_size: -20.907032150910158\n",
      "iteration: 436 grad_size: -23.82786683272291\n",
      "iteration: 437 grad_size: 12.537508666659647\n",
      "iteration: 438 grad_size: -21.653981847630845\n",
      "iteration: 439 grad_size: -19.089065265014483\n",
      "iteration: 440 grad_size: 35.48282480484971\n",
      "iteration: 441 grad_size: -3.555090649333067\n",
      "iteration: 442 grad_size: -102.7078991594168\n",
      "iteration: 443 grad_size: -58.34624245699655\n",
      "iteration: 444 grad_size: -25.40856111404417\n",
      "iteration: 445 grad_size: 12.714763322329674\n",
      "iteration: 446 grad_size: -47.18017714953032\n",
      "iteration: 447 grad_size: -10.526025261307836\n",
      "iteration: 448 grad_size: 3.119890835218996\n",
      "iteration: 449 grad_size: 35.39945836491163\n",
      "iteration: 450 grad_size: -1.9987761047067636\n",
      "iteration: 451 grad_size: 21.06518514751309\n",
      "iteration: 452 grad_size: -42.82730820154745\n",
      "iteration: 453 grad_size: 0.62348330384728\n",
      "iteration: 454 grad_size: 32.70667830441901\n",
      "iteration: 455 grad_size: -22.23641508172586\n",
      "iteration: 456 grad_size: -42.97724008489389\n",
      "iteration: 457 grad_size: -71.24024260327168\n",
      "iteration: 458 grad_size: -24.10566634538883\n",
      "iteration: 459 grad_size: 16.95833338955279\n",
      "iteration: 460 grad_size: 53.01850231759464\n",
      "iteration: 461 grad_size: -44.238987710101604\n",
      "iteration: 462 grad_size: -41.30236829284664\n",
      "iteration: 463 grad_size: -28.71433544883091\n",
      "iteration: 464 grad_size: -44.98779692354494\n",
      "iteration: 465 grad_size: 17.344973082366607\n",
      "iteration: 466 grad_size: -2.074484473946545\n",
      "iteration: 467 grad_size: -5.026977724740632\n",
      "iteration: 468 grad_size: -54.590799681451685\n",
      "iteration: 469 grad_size: -21.999276911085623\n",
      "iteration: 470 grad_size: -5.26939203479715\n",
      "iteration: 471 grad_size: 0.1987602966052222\n",
      "iteration: 472 grad_size: -6.839628390099705\n",
      "iteration: 473 grad_size: -3.7292407577853623\n",
      "iteration: 474 grad_size: -3.289558126199971\n",
      "iteration: 475 grad_size: -26.412922689351817\n",
      "iteration: 476 grad_size: -0.41252538102493475\n",
      "iteration: 477 grad_size: -4.600429316981277\n",
      "iteration: 478 grad_size: -49.22198817664719\n",
      "iteration: 479 grad_size: -5.406725424127899\n",
      "iteration: 480 grad_size: -64.94419368136491\n",
      "iteration: 481 grad_size: -5.032159920672541\n",
      "iteration: 482 grad_size: 31.14382947945652\n",
      "iteration: 483 grad_size: -85.48425339311021\n",
      "iteration: 484 grad_size: -3.4314818376047107\n",
      "iteration: 485 grad_size: 9.347371469522585\n",
      "iteration: 486 grad_size: 15.474295993473309\n",
      "iteration: 487 grad_size: 59.181678996071255\n",
      "iteration: 488 grad_size: -87.74202596788594\n",
      "iteration: 489 grad_size: 8.123664206119372\n",
      "iteration: 490 grad_size: 81.29316335408737\n",
      "iteration: 491 grad_size: 52.83695104407139\n",
      "iteration: 492 grad_size: -26.10799419678162\n",
      "iteration: 493 grad_size: -68.02690834349355\n",
      "iteration: 494 grad_size: 21.178697943728935\n",
      "iteration: 495 grad_size: -45.99409169329571\n",
      "iteration: 496 grad_size: 54.49241710307827\n",
      "iteration: 497 grad_size: -99.4899518198091\n",
      "iteration: 498 grad_size: 20.363380744704287\n",
      "iteration: 499 grad_size: 58.41541712098376\n",
      "iteration: 500 grad_size: 17.770973636316022\n",
      "iteration: 501 grad_size: -146.8399798091162\n",
      "iteration: 502 grad_size: -1.799861918885\n",
      "iteration: 503 grad_size: 17.748941854559337\n",
      "iteration: 504 grad_size: 61.04580044105573\n",
      "iteration: 505 grad_size: -85.30793143354221\n",
      "iteration: 506 grad_size: 30.30105002791914\n",
      "iteration: 507 grad_size: 10.750644351515263\n",
      "iteration: 508 grad_size: 28.755863020119143\n",
      "iteration: 509 grad_size: 26.32122211066362\n",
      "iteration: 510 grad_size: -59.58530536310465\n",
      "iteration: 511 grad_size: -2.644312088046333\n",
      "iteration: 512 grad_size: -19.50388308700915\n",
      "iteration: 513 grad_size: -44.07170320691154\n",
      "iteration: 514 grad_size: -36.09459865372361\n",
      "iteration: 515 grad_size: -37.60977922526607\n",
      "iteration: 516 grad_size: 66.44554069680868\n",
      "iteration: 517 grad_size: 41.66792929540814\n",
      "iteration: 518 grad_size: -66.56046251896619\n",
      "iteration: 519 grad_size: -65.71749596804058\n",
      "iteration: 520 grad_size: 11.846711366791737\n",
      "iteration: 521 grad_size: -42.47876725248346\n",
      "iteration: 522 grad_size: -10.788775500289688\n",
      "iteration: 523 grad_size: 51.04801964498576\n",
      "iteration: 524 grad_size: 1.6012867315652455\n",
      "iteration: 525 grad_size: 20.04437152659844\n",
      "iteration: 526 grad_size: -36.16614008345452\n",
      "iteration: 527 grad_size: 9.96967048153298\n",
      "iteration: 528 grad_size: -13.33765228174634\n",
      "iteration: 529 grad_size: -38.80292750101293\n",
      "iteration: 530 grad_size: 6.304451910356505\n",
      "iteration: 531 grad_size: 12.24174507555798\n",
      "iteration: 532 grad_size: 22.592347457997136\n",
      "iteration: 533 grad_size: 8.472227134192437\n",
      "iteration: 534 grad_size: 11.060075564362378\n",
      "iteration: 535 grad_size: -13.754643884188141\n",
      "iteration: 536 grad_size: 10.76115136234094\n",
      "iteration: 537 grad_size: 5.332992627034329\n",
      "iteration: 538 grad_size: -126.65657361296837\n",
      "iteration: 539 grad_size: 8.895865440937676\n",
      "iteration: 540 grad_size: -17.045102844329477\n",
      "iteration: 541 grad_size: -35.70913899608702\n",
      "iteration: 542 grad_size: 13.425850753147898\n",
      "iteration: 543 grad_size: -6.597970834184011\n",
      "iteration: 544 grad_size: -34.099029459585545\n",
      "iteration: 545 grad_size: -40.95321791964329\n",
      "iteration: 546 grad_size: -107.26720030561387\n",
      "iteration: 547 grad_size: 14.783057360594498\n",
      "iteration: 548 grad_size: -6.633388517573955\n",
      "iteration: 549 grad_size: 46.416995232544124\n",
      "iteration: 550 grad_size: 15.62314072314173\n",
      "iteration: 551 grad_size: -74.20331704996035\n",
      "iteration: 552 grad_size: 28.348102971002213\n",
      "iteration: 553 grad_size: 34.774737061145345\n",
      "iteration: 554 grad_size: 13.597559696601834\n",
      "iteration: 555 grad_size: -70.43028704114163\n",
      "iteration: 556 grad_size: -15.51846796412974\n",
      "iteration: 557 grad_size: 73.01972743069463\n",
      "iteration: 558 grad_size: 16.06841778719035\n",
      "iteration: 559 grad_size: -18.842129512575383\n",
      "iteration: 560 grad_size: 31.294777062179353\n",
      "iteration: 561 grad_size: -109.63398259900282\n",
      "iteration: 562 grad_size: -116.97037153835419\n",
      "iteration: 563 grad_size: 110.61473339036814\n",
      "iteration: 564 grad_size: -34.10916441698487\n",
      "iteration: 565 grad_size: 35.93823486940231\n",
      "iteration: 566 grad_size: -92.3448903294172\n",
      "iteration: 567 grad_size: 22.399354980841423\n",
      "iteration: 568 grad_size: 38.272616702632945\n",
      "iteration: 569 grad_size: -2.3874793754739017\n",
      "iteration: 570 grad_size: -84.77664565850182\n",
      "iteration: 571 grad_size: -16.11861142464307\n",
      "iteration: 572 grad_size: 1.0315214831250774\n",
      "iteration: 573 grad_size: 24.667910341417866\n",
      "iteration: 574 grad_size: 11.234844206665343\n",
      "iteration: 575 grad_size: 12.767851084369852\n",
      "iteration: 576 grad_size: -2.262385204803138\n",
      "iteration: 577 grad_size: 0.5401325059044595\n",
      "iteration: 578 grad_size: 27.604559820817975\n",
      "iteration: 579 grad_size: -64.23167526693146\n",
      "iteration: 580 grad_size: -56.592104575053284\n",
      "iteration: 581 grad_size: -17.217692186451757\n",
      "iteration: 582 grad_size: 10.933151969604651\n",
      "iteration: 583 grad_size: -18.950572264688873\n",
      "iteration: 584 grad_size: 69.9912135914885\n",
      "iteration: 585 grad_size: 42.15973308460116\n",
      "iteration: 586 grad_size: -40.30978426376719\n",
      "iteration: 587 grad_size: -6.98045400810885\n",
      "iteration: 588 grad_size: 26.12158233655768\n",
      "iteration: 589 grad_size: 23.003150391209296\n",
      "iteration: 590 grad_size: -31.939050877675427\n",
      "iteration: 591 grad_size: -99.78813945885825\n",
      "iteration: 592 grad_size: 22.639020060984592\n",
      "iteration: 593 grad_size: 28.03329399739053\n",
      "iteration: 594 grad_size: -16.065257380717057\n",
      "iteration: 595 grad_size: -63.98853695341916\n",
      "iteration: 596 grad_size: -11.110995043370295\n",
      "iteration: 597 grad_size: 45.484514718537\n",
      "iteration: 598 grad_size: -1.1385414677015433\n",
      "iteration: 599 grad_size: 27.159191971281416\n",
      "iteration: 600 grad_size: -12.519306464759865\n",
      "iteration: 601 grad_size: -11.153398516141678\n",
      "iteration: 602 grad_size: -33.750807398726025\n",
      "iteration: 603 grad_size: -8.322746365478494\n",
      "iteration: 604 grad_size: -44.84294105845936\n",
      "iteration: 605 grad_size: -119.47049102767895\n",
      "iteration: 606 grad_size: -36.069037747865124\n",
      "iteration: 607 grad_size: -31.433599463350767\n",
      "iteration: 608 grad_size: -12.928736847767254\n",
      "iteration: 609 grad_size: 65.19037709239768\n",
      "iteration: 610 grad_size: 44.857103710233986\n",
      "iteration: 611 grad_size: -11.843080703917785\n",
      "iteration: 612 grad_size: 32.72056912022502\n",
      "iteration: 613 grad_size: -34.70230940198919\n",
      "iteration: 614 grad_size: -47.45425740075818\n",
      "iteration: 615 grad_size: -33.169283022156584\n",
      "iteration: 616 grad_size: 8.943608287552287\n",
      "iteration: 617 grad_size: -32.76633181555701\n",
      "iteration: 618 grad_size: 51.14669070722812\n",
      "iteration: 619 grad_size: -8.483042407609325\n",
      "iteration: 620 grad_size: 13.273818740719278\n",
      "iteration: 621 grad_size: -14.469016715294288\n",
      "iteration: 622 grad_size: -54.919786574209965\n",
      "iteration: 623 grad_size: 68.71845086251854\n",
      "iteration: 624 grad_size: -10.763109088624176\n",
      "iteration: 625 grad_size: 8.489108962855738\n",
      "iteration: 626 grad_size: -70.28329722145001\n",
      "iteration: 627 grad_size: 31.55630696067267\n",
      "iteration: 628 grad_size: 48.424351515131704\n",
      "iteration: 629 grad_size: -9.367771705039267\n",
      "iteration: 630 grad_size: -4.8802916475003135\n",
      "iteration: 631 grad_size: -24.100975418485262\n",
      "iteration: 632 grad_size: 6.576725413844002\n",
      "iteration: 633 grad_size: 6.863570897183962\n",
      "iteration: 634 grad_size: -48.89144129508214\n",
      "iteration: 635 grad_size: 51.772566619236535\n",
      "iteration: 636 grad_size: -111.8495122866745\n",
      "iteration: 637 grad_size: 53.10542416826107\n",
      "iteration: 638 grad_size: 55.428625319407196\n",
      "iteration: 639 grad_size: -3.7808182343187866\n",
      "iteration: 640 grad_size: 15.46461104486405\n",
      "iteration: 641 grad_size: -66.5890082228372\n",
      "iteration: 642 grad_size: -56.183051121025656\n",
      "iteration: 643 grad_size: -9.999561816102101\n",
      "iteration: 644 grad_size: 17.283433945883203\n",
      "iteration: 645 grad_size: -6.850462982429818\n",
      "iteration: 646 grad_size: 29.390098916425757\n",
      "iteration: 647 grad_size: 12.117810259362251\n",
      "iteration: 648 grad_size: -46.58418132875981\n",
      "iteration: 649 grad_size: -67.6912766444907\n",
      "iteration: 650 grad_size: 23.030027419669516\n",
      "iteration: 651 grad_size: -42.011792245193085\n",
      "iteration: 652 grad_size: 4.864744581317751\n",
      "iteration: 653 grad_size: 9.265800953418669\n",
      "iteration: 654 grad_size: 37.2857092628176\n",
      "iteration: 655 grad_size: -42.504583829242975\n",
      "iteration: 656 grad_size: 42.4382979938447\n",
      "iteration: 657 grad_size: 20.75388753662611\n",
      "iteration: 658 grad_size: -14.540836015778755\n",
      "iteration: 659 grad_size: 23.45830419030119\n",
      "iteration: 660 grad_size: 2.8998867906682406\n",
      "iteration: 661 grad_size: -46.3315683560368\n",
      "iteration: 662 grad_size: -64.65010695757569\n",
      "iteration: 663 grad_size: 7.849191814692539\n",
      "iteration: 664 grad_size: 20.68641428372449\n",
      "iteration: 665 grad_size: 7.309712665725087\n",
      "iteration: 666 grad_size: 41.23306723773407\n",
      "iteration: 667 grad_size: 9.085455013900656\n",
      "iteration: 668 grad_size: -12.105147683365091\n",
      "iteration: 669 grad_size: -15.690466566082783\n",
      "iteration: 670 grad_size: -16.844677231253883\n",
      "iteration: 671 grad_size: -24.896281010144605\n",
      "iteration: 672 grad_size: 58.63402156073327\n",
      "iteration: 673 grad_size: 6.095445185900616\n",
      "iteration: 674 grad_size: -10.195756960697182\n",
      "iteration: 675 grad_size: 25.390587947341245\n",
      "iteration: 676 grad_size: -12.279338752634864\n",
      "iteration: 677 grad_size: -29.798441664654238\n",
      "iteration: 678 grad_size: -8.81450847775362\n",
      "iteration: 679 grad_size: -10.470954684780466\n",
      "iteration: 680 grad_size: -49.47084153514268\n",
      "iteration: 681 grad_size: -12.347712128107922\n",
      "iteration: 682 grad_size: -13.671294637751053\n",
      "iteration: 683 grad_size: -32.27565909827858\n",
      "iteration: 684 grad_size: 5.376189454876027\n",
      "iteration: 685 grad_size: 60.33921284583799\n",
      "iteration: 686 grad_size: 57.31489144356872\n",
      "iteration: 687 grad_size: -6.041382820836674\n",
      "iteration: 688 grad_size: -59.066267588140946\n",
      "iteration: 689 grad_size: 0.9716847477466359\n",
      "iteration: 690 grad_size: -11.513877034379341\n",
      "iteration: 691 grad_size: 20.508037657225557\n",
      "iteration: 692 grad_size: 5.8609988568889015\n",
      "iteration: 693 grad_size: -53.86794242477599\n",
      "iteration: 694 grad_size: 6.9360522897221415\n",
      "iteration: 695 grad_size: 19.31200271342051\n",
      "iteration: 696 grad_size: 6.253880680376561\n",
      "iteration: 697 grad_size: 13.244676004673892\n",
      "iteration: 698 grad_size: -7.250682173209597\n",
      "iteration: 699 grad_size: 21.66322331803552\n",
      "iteration: 700 grad_size: -33.75181636528815\n",
      "iteration: 701 grad_size: -55.32683070090562\n",
      "iteration: 702 grad_size: -54.12946680265274\n",
      "iteration: 703 grad_size: 22.671772599215416\n",
      "iteration: 704 grad_size: 27.442014297126477\n",
      "iteration: 705 grad_size: 21.969414393540287\n",
      "iteration: 706 grad_size: -0.9565018407735426\n",
      "iteration: 707 grad_size: -1.1209199120446716\n",
      "iteration: 708 grad_size: 1.5344464543375835\n",
      "iteration: 709 grad_size: -15.08733806022876\n",
      "iteration: 710 grad_size: -56.69549336461881\n",
      "iteration: 711 grad_size: 11.124178756153498\n",
      "iteration: 712 grad_size: -6.216571370371895\n",
      "iteration: 713 grad_size: 10.423305130355217\n",
      "iteration: 714 grad_size: -5.772481578541367\n",
      "iteration: 715 grad_size: 14.81352609687902\n",
      "iteration: 716 grad_size: -0.0464241046048075\n",
      "iteration: 717 grad_size: -0.27657099448742883\n",
      "iteration: 718 grad_size: 16.72317871912557\n",
      "iteration: 719 grad_size: -24.249218400260432\n",
      "iteration: 720 grad_size: 1.552660108836477\n",
      "iteration: 721 grad_size: 13.446622771909517\n",
      "iteration: 722 grad_size: -19.971899583437605\n",
      "iteration: 723 grad_size: -34.972496871030735\n",
      "iteration: 724 grad_size: -2.6741234953576196\n",
      "iteration: 725 grad_size: -0.9215200505976835\n",
      "iteration: 726 grad_size: 34.38170995173257\n",
      "iteration: 727 grad_size: 42.60822760961587\n",
      "iteration: 728 grad_size: 15.00301212613156\n",
      "iteration: 729 grad_size: -4.8027288902764695\n",
      "iteration: 730 grad_size: -18.333118165521782\n",
      "iteration: 731 grad_size: -44.91069897428818\n",
      "iteration: 732 grad_size: -33.04031194923586\n",
      "iteration: 733 grad_size: -38.53897914364675\n",
      "iteration: 734 grad_size: 1.0565571413639532\n",
      "iteration: 735 grad_size: 36.649270515794356\n",
      "iteration: 736 grad_size: 13.878893674077169\n",
      "iteration: 737 grad_size: -58.70354021591375\n",
      "iteration: 738 grad_size: -4.963652053180001\n",
      "iteration: 739 grad_size: 42.420227343629236\n",
      "iteration: 740 grad_size: 35.02891187011575\n",
      "iteration: 741 grad_size: 35.51309332751201\n",
      "iteration: 742 grad_size: -102.17711330303096\n",
      "iteration: 743 grad_size: -26.99357801137479\n",
      "iteration: 744 grad_size: 41.03675732874296\n",
      "iteration: 745 grad_size: 39.31575600948965\n",
      "iteration: 746 grad_size: 37.54059522252392\n",
      "iteration: 747 grad_size: -40.61108814372293\n",
      "iteration: 748 grad_size: -52.209743064460554\n",
      "iteration: 749 grad_size: -12.440526338075543\n",
      "iteration: 750 grad_size: 14.409611503396839\n",
      "iteration: 751 grad_size: -1.1248511055684247\n",
      "iteration: 752 grad_size: 7.370138920100501\n",
      "iteration: 753 grad_size: 1.7191528945576984\n",
      "iteration: 754 grad_size: -17.378253751435864\n",
      "iteration: 755 grad_size: -15.634221060273031\n",
      "iteration: 756 grad_size: 4.082857393003394\n",
      "iteration: 757 grad_size: 37.813514267447445\n",
      "iteration: 758 grad_size: -0.009080632979081571\n",
      "iteration: 759 grad_size: -22.392478385297522\n",
      "iteration: 760 grad_size: -16.46965383982036\n",
      "iteration: 761 grad_size: -16.453694879125273\n",
      "iteration: 762 grad_size: 3.9535857971920265\n",
      "iteration: 763 grad_size: -52.458050425670095\n",
      "iteration: 764 grad_size: -14.154452838825735\n",
      "iteration: 765 grad_size: 2.1748944486495887\n",
      "iteration: 766 grad_size: 6.696335344030004\n",
      "iteration: 767 grad_size: 39.16112101359112\n",
      "iteration: 768 grad_size: 2.429671298423804\n",
      "iteration: 769 grad_size: -20.346477853960607\n",
      "iteration: 770 grad_size: -24.156757960783956\n",
      "iteration: 771 grad_size: 98.14657771851762\n",
      "iteration: 772 grad_size: 22.598564050367727\n",
      "iteration: 773 grad_size: -15.433508141849813\n",
      "iteration: 774 grad_size: -50.37572646403223\n",
      "iteration: 775 grad_size: -14.878527258549106\n",
      "iteration: 776 grad_size: -23.925340600152133\n",
      "iteration: 777 grad_size: -32.082016349415966\n",
      "iteration: 778 grad_size: -16.359560172793252\n",
      "iteration: 779 grad_size: -44.28579890356623\n",
      "iteration: 780 grad_size: -2.0911719216443316\n",
      "iteration: 781 grad_size: -6.787598835190892\n",
      "iteration: 782 grad_size: 23.273250877697237\n",
      "iteration: 783 grad_size: 5.1691713319190455\n",
      "iteration: 784 grad_size: 5.684188459978174\n",
      "iteration: 785 grad_size: -1.1601960418457367\n",
      "iteration: 786 grad_size: -16.091024333150756\n",
      "iteration: 787 grad_size: 1.5479556361228326\n",
      "iteration: 788 grad_size: 1.5916462322778528\n",
      "iteration: 789 grad_size: -17.582177287861754\n",
      "iteration: 790 grad_size: 2.1469191912754373\n",
      "iteration: 791 grad_size: 4.610627652259405\n",
      "iteration: 792 grad_size: -14.301333051911882\n",
      "iteration: 793 grad_size: -15.070735384259237\n",
      "iteration: 794 grad_size: 19.079526124377125\n",
      "iteration: 795 grad_size: -2.8462416681371963\n",
      "iteration: 796 grad_size: -36.098893709199594\n",
      "iteration: 797 grad_size: 2.359872721029795\n",
      "iteration: 798 grad_size: 0.5054323481763987\n",
      "iteration: 799 grad_size: 5.586722171848287\n",
      "iteration: 800 grad_size: 39.582140081212955\n",
      "iteration: 801 grad_size: 1.156651699254489\n",
      "iteration: 802 grad_size: -19.49574101003379\n",
      "iteration: 803 grad_size: 1.7031778550585024\n",
      "iteration: 804 grad_size: -24.246637198105006\n",
      "iteration: 805 grad_size: -43.582363051419804\n",
      "iteration: 806 grad_size: 41.77633290734012\n",
      "iteration: 807 grad_size: 72.14994807305033\n",
      "iteration: 808 grad_size: -34.44475647348291\n",
      "iteration: 809 grad_size: -17.802488445154175\n",
      "iteration: 810 grad_size: 21.83470474903227\n",
      "iteration: 811 grad_size: 29.617390284619006\n",
      "iteration: 812 grad_size: -32.65377925484752\n",
      "iteration: 813 grad_size: 44.583509789581086\n",
      "iteration: 814 grad_size: 61.97571345984645\n",
      "iteration: 815 grad_size: -33.07524404198621\n",
      "iteration: 816 grad_size: -2.182099758749345\n",
      "iteration: 817 grad_size: -59.1779512474873\n",
      "iteration: 818 grad_size: -53.73778384313803\n",
      "iteration: 819 grad_size: 53.015004551224166\n",
      "iteration: 820 grad_size: 22.18584450623863\n",
      "iteration: 821 grad_size: -64.1838164136621\n",
      "iteration: 822 grad_size: -11.604366051555772\n",
      "iteration: 823 grad_size: -21.69336341836025\n",
      "iteration: 824 grad_size: -15.833824996628618\n",
      "iteration: 825 grad_size: 34.326743836324894\n",
      "iteration: 826 grad_size: 21.538667772286804\n",
      "iteration: 827 grad_size: 4.32170125458925\n",
      "iteration: 828 grad_size: 0.6667879182828358\n",
      "iteration: 829 grad_size: -36.09054452208099\n",
      "iteration: 830 grad_size: -51.08167294851223\n",
      "iteration: 831 grad_size: 6.003483160650632\n",
      "iteration: 832 grad_size: 82.81952794481126\n",
      "iteration: 833 grad_size: -10.817882908799628\n",
      "iteration: 834 grad_size: -63.43780715316713\n",
      "iteration: 835 grad_size: -13.071534386726952\n",
      "iteration: 836 grad_size: -1.3711842519058735\n",
      "iteration: 837 grad_size: 25.12284023226004\n",
      "iteration: 838 grad_size: 39.32675263841056\n",
      "iteration: 839 grad_size: 82.90651421749536\n",
      "iteration: 840 grad_size: 8.114342707775194\n",
      "iteration: 841 grad_size: -76.21520061898367\n",
      "iteration: 842 grad_size: 1.1805244387091918\n",
      "iteration: 843 grad_size: -18.11305988797305\n",
      "iteration: 844 grad_size: -90.79215201437381\n",
      "iteration: 845 grad_size: 31.5154751254166\n",
      "iteration: 846 grad_size: 81.12810029117432\n",
      "iteration: 847 grad_size: -44.011573847105325\n",
      "iteration: 848 grad_size: -37.032758993276815\n",
      "iteration: 849 grad_size: -44.40037536367755\n",
      "iteration: 850 grad_size: 13.95699253084176\n",
      "iteration: 851 grad_size: 65.09944288985416\n",
      "iteration: 852 grad_size: -72.58364804380817\n",
      "iteration: 853 grad_size: 6.871909716798479\n",
      "iteration: 854 grad_size: 86.65551359938249\n",
      "iteration: 855 grad_size: -14.252649245245031\n",
      "iteration: 856 grad_size: -83.71780328733921\n",
      "iteration: 857 grad_size: 5.3458454785043354\n",
      "iteration: 858 grad_size: 66.57633400898908\n",
      "iteration: 859 grad_size: -96.73109733965978\n",
      "iteration: 860 grad_size: 48.85913196690183\n",
      "iteration: 861 grad_size: 117.20801902401678\n",
      "iteration: 862 grad_size: 99.14067738428474\n",
      "iteration: 863 grad_size: -62.86040429688293\n",
      "iteration: 864 grad_size: -139.35842416303146\n",
      "iteration: 865 grad_size: -97.54200460090829\n",
      "iteration: 866 grad_size: 60.066945777906\n",
      "iteration: 867 grad_size: 30.420994698041895\n",
      "iteration: 868 grad_size: -41.92920662715524\n",
      "iteration: 869 grad_size: -64.45710927850256\n",
      "iteration: 870 grad_size: 9.55394510100923\n",
      "iteration: 871 grad_size: 60.700839343906694\n",
      "iteration: 872 grad_size: 85.35194444844394\n",
      "iteration: 873 grad_size: -68.43425293615704\n",
      "iteration: 874 grad_size: -11.385295042027366\n",
      "iteration: 875 grad_size: 41.691260891596\n",
      "iteration: 876 grad_size: 32.64909656943213\n",
      "iteration: 877 grad_size: -43.56384862356606\n",
      "iteration: 878 grad_size: 6.672245849359041\n",
      "iteration: 879 grad_size: 77.86968996105549\n",
      "iteration: 880 grad_size: -39.67444226730314\n",
      "iteration: 881 grad_size: 19.206064234776647\n",
      "iteration: 882 grad_size: 3.534409968583361\n",
      "iteration: 883 grad_size: -141.5277024142698\n",
      "iteration: 884 grad_size: 61.796957996126174\n",
      "iteration: 885 grad_size: 3.439482567931635\n",
      "iteration: 886 grad_size: -32.0855440290932\n",
      "iteration: 887 grad_size: -61.80121556250354\n",
      "iteration: 888 grad_size: 0.6742996095017872\n",
      "iteration: 889 grad_size: 38.044250408445066\n",
      "iteration: 890 grad_size: -14.902893957708244\n",
      "iteration: 891 grad_size: -34.36599406202545\n",
      "iteration: 892 grad_size: -10.603709329221816\n",
      "iteration: 893 grad_size: 47.725197323127986\n",
      "iteration: 894 grad_size: 0.2675210799215364\n",
      "iteration: 895 grad_size: 24.800361404200288\n",
      "iteration: 896 grad_size: 44.17769555945793\n",
      "iteration: 897 grad_size: 44.878004177494844\n",
      "iteration: 898 grad_size: 7.797082125500959\n",
      "iteration: 899 grad_size: -106.81952073200647\n",
      "iteration: 900 grad_size: -7.50272935069907\n",
      "iteration: 901 grad_size: 9.624131822953963\n",
      "iteration: 902 grad_size: -54.19089296305007\n",
      "iteration: 903 grad_size: -8.322894435859737\n",
      "iteration: 904 grad_size: -30.716351998015526\n",
      "iteration: 905 grad_size: -33.52650479359839\n",
      "iteration: 906 grad_size: 100.05323510508259\n",
      "iteration: 907 grad_size: 63.694620755063625\n",
      "iteration: 908 grad_size: -14.875130102837872\n",
      "iteration: 909 grad_size: -14.810478017833887\n",
      "iteration: 910 grad_size: -14.803035501507722\n",
      "iteration: 911 grad_size: -6.574116210203357\n",
      "iteration: 912 grad_size: 62.75201358406611\n",
      "iteration: 913 grad_size: 6.164455974961484\n",
      "iteration: 914 grad_size: -75.5164860356749\n",
      "iteration: 915 grad_size: -83.97393607157025\n",
      "iteration: 916 grad_size: -15.938168644525064\n",
      "iteration: 917 grad_size: 62.47370207460028\n",
      "iteration: 918 grad_size: 23.772579447941197\n",
      "iteration: 919 grad_size: 6.652615930866347\n",
      "iteration: 920 grad_size: -32.87624567665573\n",
      "iteration: 921 grad_size: -20.57918270661071\n",
      "iteration: 922 grad_size: -12.228036351605482\n",
      "iteration: 923 grad_size: 6.226019457829665\n",
      "iteration: 924 grad_size: 2.790632588024323\n",
      "iteration: 925 grad_size: -0.5751846013487523\n",
      "iteration: 926 grad_size: -55.72982617554129\n",
      "iteration: 927 grad_size: 6.448691876830878\n",
      "iteration: 928 grad_size: 14.76462824065247\n",
      "iteration: 929 grad_size: 72.02499985894613\n",
      "iteration: 930 grad_size: 20.366216210529068\n",
      "iteration: 931 grad_size: 21.778981503553396\n",
      "iteration: 932 grad_size: -56.68757309435162\n",
      "iteration: 933 grad_size: -53.82926318903777\n",
      "iteration: 934 grad_size: 6.428594588636287\n",
      "iteration: 935 grad_size: 71.12658904767375\n",
      "iteration: 936 grad_size: 11.98723712642014\n",
      "iteration: 937 grad_size: 3.031477642001761\n",
      "iteration: 938 grad_size: -35.75003633624201\n",
      "iteration: 939 grad_size: 4.5938327434858195\n",
      "iteration: 940 grad_size: 12.00496746715703\n",
      "iteration: 941 grad_size: 95.37031008203927\n",
      "iteration: 942 grad_size: 1.0329766935660203\n",
      "iteration: 943 grad_size: -83.18076406993276\n",
      "iteration: 944 grad_size: 7.028299019652906\n",
      "iteration: 945 grad_size: -82.92258748280894\n",
      "iteration: 946 grad_size: -48.10850398427815\n",
      "iteration: 947 grad_size: 10.442302462777548\n",
      "iteration: 948 grad_size: -22.317160179995604\n",
      "iteration: 949 grad_size: -37.63489702607029\n",
      "iteration: 950 grad_size: -9.725603447543339\n",
      "iteration: 951 grad_size: 7.496785887223375\n",
      "iteration: 952 grad_size: 56.75106972378554\n",
      "iteration: 953 grad_size: 15.52058845337919\n",
      "iteration: 954 grad_size: -74.03123164511551\n",
      "iteration: 955 grad_size: 17.04563233541697\n",
      "iteration: 956 grad_size: -11.440955988789398\n",
      "iteration: 957 grad_size: 32.52047260159587\n",
      "iteration: 958 grad_size: -14.570590701306088\n",
      "iteration: 959 grad_size: -21.003452732595207\n",
      "iteration: 960 grad_size: 59.499247437022134\n",
      "iteration: 961 grad_size: 50.066699498687775\n",
      "iteration: 962 grad_size: -20.72358824716988\n",
      "iteration: 963 grad_size: -10.044535576096777\n",
      "iteration: 964 grad_size: -18.67456625619939\n",
      "iteration: 965 grad_size: -17.73885116485306\n",
      "iteration: 966 grad_size: -14.580137823341886\n",
      "iteration: 967 grad_size: 58.85074300350807\n",
      "iteration: 968 grad_size: -15.329454091680123\n",
      "iteration: 969 grad_size: -11.84921229029922\n",
      "iteration: 970 grad_size: 31.27949109268669\n",
      "iteration: 971 grad_size: 32.764564864460155\n",
      "iteration: 972 grad_size: -19.10253781206248\n",
      "iteration: 973 grad_size: -21.853400355882528\n",
      "iteration: 974 grad_size: -22.009446797284056\n",
      "iteration: 975 grad_size: -17.629326553419073\n",
      "iteration: 976 grad_size: 8.438074556798284\n",
      "iteration: 977 grad_size: -0.6821540086546065\n",
      "iteration: 978 grad_size: -20.016767807399127\n",
      "iteration: 979 grad_size: -13.821262752902406\n",
      "iteration: 980 grad_size: -10.351810365413769\n",
      "iteration: 981 grad_size: -11.15386650112707\n",
      "iteration: 982 grad_size: -11.792637796113677\n",
      "iteration: 983 grad_size: 47.09198053644346\n",
      "iteration: 984 grad_size: -20.658204926538627\n",
      "iteration: 985 grad_size: 49.104161988270704\n",
      "iteration: 986 grad_size: -55.15170347648016\n",
      "iteration: 987 grad_size: 23.408898821932837\n",
      "iteration: 988 grad_size: 6.635673425432074\n",
      "iteration: 989 grad_size: -19.715730462587633\n",
      "iteration: 990 grad_size: -18.951970538791777\n",
      "iteration: 991 grad_size: -34.42788733877072\n",
      "iteration: 992 grad_size: -17.062468251080933\n",
      "iteration: 993 grad_size: 4.856071161060996\n",
      "iteration: 994 grad_size: -39.45157528146753\n",
      "iteration: 995 grad_size: 10.894753650698142\n",
      "iteration: 996 grad_size: 10.36164724164664\n",
      "iteration: 997 grad_size: 7.584379966336286\n",
      "iteration: 998 grad_size: -17.025073494610663\n",
      "iteration: 999 grad_size: 47.091317404260586\n"
     ]
    }
   ],
   "source": [
    "svm = SVM(11, num_iterations=1000, learning_rate=0.00001)\n",
    "svm.fit(x_train.drop(\"HeartDisease\",axis=1).to_numpy(),x_train[\"HeartDisease\"].astype(int).to_numpy(), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55 27]\n",
      " [11 91]]\n",
      "0.8921568627450981\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test.to_numpy().astype(np.int16),svm.predict(x_test.to_numpy()) > 0))\n",
    "print(recall_score(y_test.to_numpy().astype(np.int16),svm.predict(x_test.to_numpy()) > 0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LeafNode():\n",
    "    value: int\n",
    "\n",
    "\n",
    "@dataclass    \n",
    "class Node():\n",
    "    depth: int\n",
    "    column_index: int\n",
    "    column_value: int\n",
    "    left_child: Self | LeafNode | None = None\n",
    "    right_child: Self | LeafNode | None = None\n",
    "\n",
    "@dataclass\n",
    "class BuildingNode():\n",
    "    depth: int\n",
    "    data: pd.DataFrame\n",
    "    parent: Node| None = None\n",
    "    is_left_child: bool = True\n",
    "\n",
    "    def _add_to_parent(self, node: LeafNode | Node):\n",
    "        if self.parent is not None:\n",
    "            if self.is_left_child:\n",
    "                self.parent.left_child = node\n",
    "            else:\n",
    "                self.parent.right_child = node\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Cut():\n",
    "    gain: float\n",
    "    column_index: int\n",
    "    value: int | float\n",
    "\n",
    "class DecisionTree():\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.root = None\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        x: pd.DataFrame,\n",
    "        target_index: int,\n",
    "        min_samples_split = 30,\n",
    "        min_gain = 0.01,\n",
    "        max_depth = 6\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Fit the model with data\n",
    "\n",
    "        Args:\n",
    "            x (pd.DataFrame): Fitting data.\n",
    "            target_index (int): Column index of target feature to predict in data\n",
    "            min_samples_split (int, optional): Minimal samples to concider for cut. Defaults to 30.\n",
    "            min_gain (float, optional): Minimal acceptable information gain from cut. Defaults to 0.01.\n",
    "            max_depth (int, optional): Maximal depth of tree. Defaults to 6.\n",
    "        \"\"\"\n",
    "        stack: Deque[\"BuildingNode\"] = deque()\n",
    "        stack.append(BuildingNode(0,x.copy(deep=False)))\n",
    "\n",
    "        while True:\n",
    "            print()\n",
    "            print(len(stack))\n",
    "            if len(stack) == 0:\n",
    "                return\n",
    "            splitting_node  = stack.pop()\n",
    "            print(f\"depth:{splitting_node.depth} shape: {splitting_node.data.shape}, is left: {splitting_node.is_left_child}\")\n",
    "\n",
    "            #=== finding minimal split and checking end conditions =======\n",
    "            if splitting_node.data.shape[0] <= min_samples_split or splitting_node.depth == max_depth :\n",
    "                self._create_leaf_node(splitting_node, target_index)\n",
    "                continue\n",
    "\n",
    "            cut = self._find_cut(splitting_node.data, target_index)\n",
    "            print(f\"gain: {cut.gain}, column: {cut.column_index}\")\n",
    "\n",
    "            if cut.gain <= min_gain:\n",
    "                self._create_leaf_node(splitting_node, target_index)\n",
    "                continue\n",
    "            #======================+=======================================\n",
    "\n",
    "            #=== adding non leaf node ========\n",
    "            new_node = Node(splitting_node.depth,cut.column_index, cut.value) # type: ignore\n",
    "            if self.root is None:\n",
    "                self.root = new_node\n",
    "            else:\n",
    "                splitting_node._add_to_parent(new_node)\n",
    "            #=================================\n",
    "\n",
    "            #=== creating and adding left and right nodes to cut =======\n",
    "            right_x = splitting_node.data[splitting_node.data.iloc[:,cut.column_index] != cut.value]\n",
    "            stack.append(BuildingNode(splitting_node.depth + 1, right_x, new_node, is_left_child= False))\n",
    "            left_x = splitting_node.data[splitting_node.data.iloc[:,cut.column_index] == cut.value]\n",
    "            stack.append(BuildingNode(splitting_node.depth + 1, left_x,new_node))\n",
    "            #============================================================\n",
    "\n",
    "            print(f\"left: {left_x.shape}, right: {right_x.shape}\")\n",
    "\n",
    "    def predict(self, x: pd.DataFrame) -> list:\n",
    "        \"\"\"\n",
    "        predicting data\n",
    "\n",
    "        Args:\n",
    "            x (pd.DataFrame): dataframe without target column\n",
    "\n",
    "        Raises:\n",
    "            Exception: When the data aren't in right format\n",
    "\n",
    "        Returns:\n",
    "            list: predicted value for each row\n",
    "        \"\"\"\n",
    "        if self.root == None:\n",
    "            raise Exception(\"Tree ins't built\")\n",
    "        result = []\n",
    "        for _,row in x.iterrows(): #HACK: slow solution\n",
    "            result.append(int(self._find_result(row,self.root)))\n",
    "        return result\n",
    "    \n",
    "    def _find_result(self, row:pd.Series, node: Node | LeafNode) -> int:\n",
    "        \"\"\"\n",
    "        Recursively traverse the tree.\n",
    "\n",
    "        Args:\n",
    "            row (pd.Series): Row to predict without targeted column.\n",
    "            node (Node | LeafNode, Optional): Current node in tree.\n",
    "\n",
    "        Returns:\n",
    "            int: value \n",
    "        \"\"\"\n",
    "\n",
    "        if type(node) is LeafNode:\n",
    "            return node.value\n",
    "        elif row[node.column_index] == node.column_value: # type: ignore\n",
    "            return self._find_result(row, node.left_child) # type: ignore\n",
    "        return self._find_result(row,node.right_child) # type: ignore\n",
    "        \n",
    "\n",
    "    def _create_leaf_node(self, splitting_node: BuildingNode, target_index: int) -> None:\n",
    "            leaf_node = LeafNode(value=splitting_node.data.iloc[:,target_index].mode()[0])\n",
    "            splitting_node._add_to_parent(leaf_node)\n",
    "\n",
    "    def _find_cut(self, x: pd.DataFrame, target_index: int) -> Cut:\n",
    "        \"\"\"\n",
    "        Find the best cut for given data.\n",
    "\n",
    "        Args:\n",
    "            x (pd.DataFrame): Fitting data for splitting.\n",
    "            target_index (int): Index column with targeted feature.\n",
    "\n",
    "        Raises:\n",
    "            Exception: If there are not any possible cut.\n",
    "\n",
    "        Returns:\n",
    "            Cut: Best cut for current data.\n",
    "        \"\"\"\n",
    "        pre_cut_impurity = self._qini_impurity(x.iloc[:,target_index])\n",
    "        best_cut = Cut(0,0,float(\"inf\"))\n",
    "\n",
    "        for column_index,_ in enumerate(x.columns):\n",
    "            if x.columns[target_index] == x.columns[column_index]:\n",
    "                continue\n",
    "            best_column_cut = self._best_cut(\n",
    "                x,\n",
    "                index = column_index,\n",
    "                pre_cut_impurity = pre_cut_impurity,\n",
    "                target_index = target_index\n",
    "            )\n",
    "            if best_column_cut.gain > best_cut.gain:\n",
    "                best_cut = best_column_cut\n",
    "\n",
    "        if type(best_cut.value) is inf:\n",
    "            raise Exception(\"Cut wasn't found.\")\n",
    "        return  best_cut\n",
    "\n",
    "    def _best_cut(\n",
    "        self,\n",
    "        x: pd.DataFrame,\n",
    "        index: int,\n",
    "        pre_cut_impurity: float,\n",
    "        target_index: int\n",
    "    ) -> Cut:\n",
    "        \"\"\"\n",
    "        Find best cut for specified feature.\n",
    "\n",
    "        Args:\n",
    "            x (pd.DataFrame): Fitting data.\n",
    "            index (int): Index of splitting feature.\n",
    "            pre_cut_impurity (float): Precomputed qini impurity for pre_splitted data.\n",
    "            target_index (int): Column index with target feature.\n",
    "\n",
    "        Returns:\n",
    "            Cut: Best feature cut.\n",
    "        \"\"\"\n",
    "\n",
    "        def best_continuous_cut(\n",
    "            x: pd.DataFrame,\n",
    "            index: int,\n",
    "            pre_cut_impurity: float,\n",
    "            target_index: int\n",
    "        ) -> Cut:\n",
    "            best_cut = Cut(0,index,float(\"inf\"))\n",
    "            diffs = x.iloc[:,index].sort_values().diff()\n",
    "\n",
    "            for diff in diffs: #HACK: lot of values really slow\n",
    "                gain =self._information_gain(pre_cut_impurity, x[x.iloc[:,index] <= diff].iloc[:,target_index])\n",
    "                if gain > best_cut.value:\n",
    "                    best_cut = Cut(gain,index,gain)\n",
    "            if type(best_cut.value) is inf:\n",
    "                raise Exception(\" cut wasn't found on column.\")\n",
    "            return best_cut\n",
    "\n",
    "        def best_categorical_cut(\n",
    "                x: pd.DataFrame,\n",
    "                index: int,\n",
    "                pre_cut_impurity: float,\n",
    "                target_index\n",
    "        ) -> Cut:\n",
    "            unique_values = x.iloc[:,index].unique()\n",
    "            # if x[:,target_index].unique().shape[0] == unique.shape[0] == 2:\n",
    "            #     return pre_cut_impurity - x[x.iloc[:,index] == unique[0]].iloc[:,target_index]\n",
    "            best_cut = Cut(0,index,float(\"inf\"))\n",
    "\n",
    "            for unique_value in unique_values:\n",
    "                gain = self._information_gain(pre_cut_impurity, x[x.iloc[:,index] == unique_value].iloc[:,target_index])\n",
    "                if gain > best_cut.gain:\n",
    "                    best_cut = Cut(gain,index,unique_value)\n",
    "            if type(best_cut.value) is inf:\n",
    "                raise Exception(\" cut wasn't found on column.\")\n",
    "            return best_cut\n",
    "        \n",
    "        if x.iloc[:,index].dtype.name == \"category\":\n",
    "            return best_categorical_cut(\n",
    "                x = x,\n",
    "                index = index,\n",
    "                pre_cut_impurity = pre_cut_impurity,\n",
    "                target_index = target_index\n",
    "            )\n",
    "        return best_continuous_cut(\n",
    "            x = x,\n",
    "            index = index,\n",
    "            pre_cut_impurity = pre_cut_impurity, \n",
    "            target_index= target_index \n",
    "        )    \n",
    "        \n",
    "    def _information_gain(self, pre_cut_impurity, x:pd.Series) -> float: \n",
    "        return pre_cut_impurity - self._qini_impurity(x)\n",
    "    \n",
    "    def _qini_impurity(self, x: pd.Series) -> float:\n",
    "        p = x.value_counts()/x.shape[0]\n",
    "        return 1 - np.sum(p**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1\n",
      "depth:0 shape: (734, 11), is left: True\n",
      "gain: 0.2468832719204046, column: 2\n",
      "left: (148, 11), right: (586, 11)\n",
      "\n",
      "2\n",
      "depth:1 shape: (148, 11), is left: True\n",
      "gain: 0.05023998350253167, column: 6\n",
      "left: (105, 11), right: (43, 11)\n",
      "\n",
      "3\n",
      "depth:2 shape: (105, 11), is left: True\n",
      "gain: 0.0423364227187315, column: 8\n",
      "left: (97, 11), right: (8, 11)\n",
      "\n",
      "4\n",
      "depth:3 shape: (97, 11), is left: True\n",
      "gain: 0.018615958233649477, column: 1\n",
      "left: (35, 11), right: (62, 11)\n",
      "\n",
      "5\n",
      "depth:4 shape: (35, 11), is left: True\n",
      "gain: 0.20244897959183672, column: 5\n",
      "left: (1, 11), right: (34, 11)\n",
      "\n",
      "6\n",
      "depth:5 shape: (1, 11), is left: True\n",
      "\n",
      "5\n",
      "depth:5 shape: (34, 11), is left: False\n",
      "gain: 0, column: 0\n",
      "\n",
      "4\n",
      "depth:4 shape: (62, 11), is left: False\n",
      "gain: 0.005881814224128812, column: 5\n",
      "\n",
      "3\n",
      "depth:3 shape: (8, 11), is left: False\n",
      "\n",
      "2\n",
      "depth:2 shape: (43, 11), is left: False\n",
      "gain: 0.10436063272977603, column: 6\n",
      "left: (22, 11), right: (21, 11)\n",
      "\n",
      "3\n",
      "depth:3 shape: (22, 11), is left: True\n",
      "\n",
      "2\n",
      "depth:3 shape: (21, 11), is left: False\n",
      "\n",
      "1\n",
      "depth:1 shape: (586, 11), is left: False\n",
      "gain: 0.10055741577902999, column: 8\n",
      "left: (281, 11), right: (305, 11)\n",
      "\n",
      "2\n",
      "depth:2 shape: (281, 11), is left: True\n",
      "gain: 0.06895096370037157, column: 1\n",
      "left: (31, 11), right: (250, 11)\n",
      "\n",
      "3\n",
      "depth:3 shape: (31, 11), is left: True\n",
      "gain: 0.10868180363829227, column: 6\n",
      "left: (19, 11), right: (12, 11)\n",
      "\n",
      "4\n",
      "depth:4 shape: (19, 11), is left: True\n",
      "\n",
      "3\n",
      "depth:4 shape: (12, 11), is left: False\n",
      "\n",
      "2\n",
      "depth:3 shape: (250, 11), is left: False\n",
      "gain: 0.04867822222222229, column: 2\n",
      "left: (36, 11), right: (214, 11)\n",
      "\n",
      "3\n",
      "depth:4 shape: (36, 11), is left: True\n",
      "gain: 0.4027777777777778, column: 6\n",
      "left: (6, 11), right: (30, 11)\n",
      "\n",
      "4\n",
      "depth:5 shape: (6, 11), is left: True\n",
      "\n",
      "3\n",
      "depth:5 shape: (30, 11), is left: False\n",
      "\n",
      "2\n",
      "depth:4 shape: (214, 11), is left: False\n",
      "gain: 0.034491421589387894, column: 6\n",
      "left: (117, 11), right: (97, 11)\n",
      "\n",
      "3\n",
      "depth:5 shape: (117, 11), is left: True\n",
      "gain: 0.42428227043611655, column: 2\n",
      "left: (1, 11), right: (116, 11)\n",
      "\n",
      "4\n",
      "depth:6 shape: (1, 11), is left: True\n",
      "\n",
      "3\n",
      "depth:6 shape: (116, 11), is left: False\n",
      "\n",
      "2\n",
      "depth:5 shape: (97, 11), is left: False\n",
      "gain: 0.05605226353485515, column: 6\n",
      "left: (54, 11), right: (43, 11)\n",
      "\n",
      "3\n",
      "depth:6 shape: (54, 11), is left: True\n",
      "\n",
      "2\n",
      "depth:6 shape: (43, 11), is left: False\n",
      "\n",
      "1\n",
      "depth:2 shape: (305, 11), is left: False\n",
      "gain: 0.05271490717951732, column: 2\n",
      "left: (124, 11), right: (181, 11)\n",
      "\n",
      "2\n",
      "depth:3 shape: (124, 11), is left: True\n",
      "gain: 0.05675368250664825, column: 6\n",
      "left: (75, 11), right: (49, 11)\n",
      "\n",
      "3\n",
      "depth:4 shape: (75, 11), is left: True\n",
      "gain: 0.031305630708752585, column: 5\n",
      "left: (62, 11), right: (13, 11)\n",
      "\n",
      "4\n",
      "depth:5 shape: (62, 11), is left: True\n",
      "gain: 0.03856748714437719, column: 1\n",
      "left: (41, 11), right: (21, 11)\n",
      "\n",
      "5\n",
      "depth:6 shape: (41, 11), is left: True\n",
      "\n",
      "4\n",
      "depth:6 shape: (21, 11), is left: False\n",
      "\n",
      "3\n",
      "depth:5 shape: (13, 11), is left: False\n",
      "\n",
      "2\n",
      "depth:4 shape: (49, 11), is left: False\n",
      "gain: 0.11788629017032992, column: 1\n",
      "left: (17, 11), right: (32, 11)\n",
      "\n",
      "3\n",
      "depth:5 shape: (17, 11), is left: True\n",
      "\n",
      "2\n",
      "depth:5 shape: (32, 11), is left: False\n",
      "gain: 0.014044777882797788, column: 5\n",
      "left: (23, 11), right: (9, 11)\n",
      "\n",
      "3\n",
      "depth:6 shape: (23, 11), is left: True\n",
      "\n",
      "2\n",
      "depth:6 shape: (9, 11), is left: False\n",
      "\n",
      "1\n",
      "depth:3 shape: (181, 11), is left: False\n",
      "gain: 0.022268489161762828, column: 5\n",
      "left: (123, 11), right: (58, 11)\n",
      "\n",
      "2\n",
      "depth:4 shape: (123, 11), is left: True\n",
      "gain: 0.05573233625721841, column: 6\n",
      "left: (19, 11), right: (104, 11)\n",
      "\n",
      "3\n",
      "depth:5 shape: (19, 11), is left: True\n",
      "\n",
      "2\n",
      "depth:5 shape: (104, 11), is left: False\n",
      "gain: 0.012856153309450002, column: 1\n",
      "left: (84, 11), right: (20, 11)\n",
      "\n",
      "3\n",
      "depth:6 shape: (84, 11), is left: True\n",
      "\n",
      "2\n",
      "depth:6 shape: (20, 11), is left: False\n",
      "\n",
      "1\n",
      "depth:4 shape: (58, 11), is left: False\n",
      "gain: 0.024116127843125, column: 2\n",
      "left: (46, 11), right: (12, 11)\n",
      "\n",
      "2\n",
      "depth:5 shape: (46, 11), is left: True\n",
      "gain: 0.11842865846990258, column: 6\n",
      "left: (11, 11), right: (35, 11)\n",
      "\n",
      "3\n",
      "depth:6 shape: (11, 11), is left: True\n",
      "\n",
      "2\n",
      "depth:6 shape: (35, 11), is left: False\n",
      "\n",
      "1\n",
      "depth:5 shape: (12, 11), is left: False\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTree()\n",
    "tree.fit(x_train,-1,min_gain=0.01, max_depth=6)\n",
    "pred = tree.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49 33]\n",
      " [13 89]]\n",
      "0.8725490196078431\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test.astype(int),pred))\n",
    "print(recall_score(y_test.astype(int),pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## naivnÃ­ Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Probability():\n",
    "\n",
    "    def get_probability(self):\n",
    "        pass\n",
    "\n",
    "@dataclass\n",
    "class CategoricalProbability(Probability):\n",
    "    categories: dict[Any,float] \n",
    "\n",
    "    def get_probability(self, value: Any):\n",
    "        return self.categories[value]\n",
    "\n",
    "@dataclass\n",
    "class ContinuousLikelihood(Probability):\n",
    "    dist: NormalDist\n",
    "\n",
    "    def get_probability(self, value: float):\n",
    "        return self.dist.pdf(value)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Probabilities():\n",
    "    probabilities: dict[Any,list[Probability]]\n",
    "    target_values: list = field(init=False)\n",
    "    size_column: int = field(init=False)\n",
    "\n",
    "    def get_probability(self, target_value, index, value)-> float:\n",
    "        return self.probabilities[target_value][index].get_probability(value)\n",
    "        \n",
    "    def __post_init__(self):\n",
    "        self.target_values = list(self.probabilities.keys())\n",
    "        self.size_column = len(self.probabilities[self.target_values[0]])\n",
    "\n",
    "class NaiveBayes():\n",
    "\n",
    "    def __init__(self, alpha: int = 1) -> None:\n",
    "        self._alpha = alpha\n",
    "\n",
    "\n",
    "    def fit(self, x: pd.DataFrame, target_index: int) -> None:\n",
    "        \"\"\"\n",
    "        Fit the model with data.\n",
    "\n",
    "        Args:\n",
    "            x (pd.DataFrame): data\n",
    "            target_index (int): column index of target feature to predict in data\n",
    "        \"\"\"\n",
    "        probabilities = {}\n",
    "        total = x.shape[0]\n",
    "        y = x.pop(str(x.columns[target_index]))\n",
    "\n",
    "        for target_value in y.unique():\n",
    "            filtered_data = x[x.iloc[:,target_index] == target_value]\n",
    "            probabilities[target_value] = []\n",
    "            for column in x.columns:\n",
    "                probabilities[target_value].append(self._calculate_probabilities(filtered_data[column], total))\n",
    "        self._probabilities = Probabilities(probabilities)\n",
    "\n",
    "\n",
    "    def predict(self, rows: pd.DataFrame)-> list:\n",
    "        \"\"\"\n",
    "        Predict values for given rows.\n",
    "\n",
    "        Args:\n",
    "            rows (pd.DataFrame): Rows of predicting data without target column.\n",
    "\n",
    "        Returns:\n",
    "            list: Predicted values for each row.\n",
    "        \"\"\"\n",
    "        probabilities = []\n",
    "        for _,row in rows.iterrows(): # HACK: slow solution\n",
    "            probabilities .append(self._get_category(row))\n",
    "        return probabilities\n",
    "\n",
    "    \n",
    "    def _get_category(self, row: pd.Series) -> Any:\n",
    "        \"\"\"\n",
    "        Calculate probability for all classes.\n",
    "\n",
    "        Args:\n",
    "            row (pd.Series): Row to predict.\n",
    "\n",
    "        Returns:\n",
    "            Any : Category with biggest probability.\n",
    "        \"\"\"\n",
    "        max_prob = -9999\n",
    "        target = None\n",
    "        for target_value in self._probabilities.target_values:\n",
    "            probability = 1\n",
    "            for index_column in range(self._probabilities.size_column):\n",
    "                probability *= np.log(self._probabilities.get_probability(target_value,index_column,row.iloc[index_column]))\n",
    "            if probability > max_prob:\n",
    "                max_prob = probability\n",
    "                target = target_value\n",
    "        return target\n",
    "\n",
    "\n",
    "    def _calculate_probabilities(self, x: pd.Series, total: int) -> Probability:\n",
    "        \"\"\"\n",
    "        Calculate probability metrics.\n",
    "\n",
    "        Args:\n",
    "            x (pd.Series): Feature ( column )\n",
    "\n",
    "        Returns:\n",
    "            Probability: return Probability object for given class ( category or continous ) which can calculate probability.\n",
    "        \"\"\"\n",
    "        if x.dtype.name == \"category\":\n",
    "            probabilities = {}\n",
    "            for index, value in x.value_counts().items():\n",
    "                probabilities[index] = ((value + self._alpha) / (total + self._alpha))\n",
    "            return CategoricalProbability(probabilities) \n",
    "        return ContinuousLikelihood(NormalDist(mu=x.mean() ,sigma = x.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_classifier = NaiveBayes()\n",
    "bayes_classifier.fit(x_train,-1)\n",
    "pred = bayes_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "[[ 0 82]\n",
      " [17 85]]\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(y_test.astype(int),pred))\n",
    "print(confusion_matrix(y_test.astype(int),pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
